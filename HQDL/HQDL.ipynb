{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35.10\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import collections\n",
    "import ast\n",
    "import time\n",
    "import collections\n",
    "import json\n",
    "import sqlite3\n",
    "import xxhash\n",
    "import numpy as np\n",
    "import pickle \n",
    "import random\n",
    "import glob\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "print(openai.__version__)\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time\n",
    "from multiprocessing import Process, Queue\n",
    "import query_module\n",
    "def evalfunc(sql_source, sql_target, db_path_source, db_path_target):\n",
    "    if not os.path.isfile(db_path_source):\n",
    "        print(\"cannot find file\", db_path_source)\n",
    "        return False\n",
    "    if not os.path.isfile(db_path_target):\n",
    "        print(\"cannot find file\", db_path_target)\n",
    "        return False\n",
    "    timeout = 120\n",
    "    output = Queue()\n",
    "    query_process = Process(target=query_module.execute_query, args=(db_path_source, sql_source, output))\n",
    "    query_process.start()\n",
    "    output_hash = ''\n",
    "    \n",
    "    try:\n",
    "        source_results = None\n",
    "        source_results = output.get(True, timeout+5)\n",
    "        query_process.join(timeout)\n",
    "        if query_process.is_alive():\n",
    "            print(\"process terminated\")\n",
    "            query_process.terminate()  # Terminate the process\n",
    "            query_process.join()  # Make sure it's cleaned up\n",
    "            return False, [Exception('SQL query took too much time to execute.')]\n",
    "        if isinstance(source_results, Exception):\n",
    "            raise source_results\n",
    "        output_hash = xxhash.xxh128_hexdigest(str(len(source_results)), seed=123)\n",
    "        connection = sqlite3.connect(db_path_target)\n",
    "        cursor = connection.cursor()\n",
    "        target_results = cursor.execute(sql_target).fetchall()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        if len(source_results) != len(target_results):\n",
    "            return False, []\n",
    "        if 'ORDER BY' in sql_target:\n",
    "            for a, b in zip(source_results, target_results):\n",
    "                lhs = tuple(sorted(list(a), key=lambda x: hash(x)))\n",
    "                rhs = tuple(sorted(list(b), key=lambda x: hash(x)))\n",
    "                output_hash = xxhash.xxh128_hexdigest(output_hash + str(lhs), seed=123)\n",
    "                if lhs != rhs:\n",
    "                    return False, []\n",
    "        else:\n",
    "            lset, rset = set(), set()\n",
    "            for a, b in zip(source_results, target_results):\n",
    "                lset.add(tuple(sorted(list(a), key=lambda x: hash(x))))\n",
    "                rset.add(tuple(sorted(list(b), key=lambda x: hash(x))))\n",
    "            output_hash = xxhash.xxh128_hexdigest(str(lset), seed=123)\n",
    "            if lset != rset:\n",
    "                return False, []\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return False, [ex]\n",
    "    return True, []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(sql, db_path):\n",
    "    if not os.path.isfile(db_path):\n",
    "        print(\"cannot find file\")\n",
    "        return False\n",
    "    results = ''\n",
    "    try:\n",
    "        connection = sqlite3.connect(db_path, uri=True)\n",
    "        cursor = connection.cursor()\n",
    "        results = cursor.execute(sql).fetchall()\n",
    "    except Exception as ex:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(ex)\n",
    "        return False\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the key used\n",
    "prefix_keys = {}\n",
    "prefix_keys = pickle.load(open(\"prefix_keys.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Califronia Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "from SQLs import create_california_llm_table, california_llm_table_insert_records\n",
    "database = 'california_schools'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('DROP TABLE IF EXISTS llm;')\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(create_california_llm_table)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "# modify\n",
    "output_name = './llm_generations/5-shots/california_schools_gpt4turbo_5shot.jsonl'\n",
    "\n",
    "\n",
    "rows = []\n",
    "identifier_2_caschools_record = {}\n",
    "with open(output_name, 'r') as outfile:\n",
    "    for line in outfile:\n",
    "        response = json.loads(line)\n",
    "        rid = response['custom_id']\n",
    "        result = response['response']['body'][\"choices\"][0]['message']['content']\n",
    "        result = result.replace(\", '\", \",'\")\n",
    "        result = result.replace(\"'s\", '\\\"s')\n",
    "        data_io = StringIO(result)\n",
    "        reader = csv.reader(data_io, delimiter=',', quotechar=\"'\")\n",
    "        if 'fprm' in rid:\n",
    "            fprm_entry = next(reader)\n",
    "            fprm_entry = [str(e.strip()) for e in fprm_entry]\n",
    "            if len(fprm_entry) < 5:\n",
    "                fprm_entry = prefix_keys[rid] + fprm_entry\n",
    "            elif len(fprm_entry)>5:\n",
    "                num_to_concat = len(fprm_entry) - 5 + 1\n",
    "                concatenated_value = ' '.join(fprm_entry[:num_to_concat])\n",
    "                fprm_entry = [concatenated_value] + fprm_entry[num_to_concat:]\n",
    "            if len(fprm_entry) != 5:\n",
    "                continue\n",
    "            # make sure keys are the same\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                fprm_entry[i] = key\n",
    "            for i in range(7):\n",
    "                fprm_entry.append(None)\n",
    "            rows.append(tuple(fprm_entry))\n",
    "        else:\n",
    "            school_entry = next(reader)\n",
    "            school_entry = [str(e.strip()) for e in school_entry]\n",
    "            if len(school_entry) < 7:\n",
    "                school_entry = prefix_keys[rid] + school_entry\n",
    "            elif len(school_entry) > 7:\n",
    "                num_to_concat = len(school_entry) - 7 + 1\n",
    "                concatenated_value = ' '.join(school_entry[:num_to_concat])\n",
    "                school_entry = [concatenated_value] + school_entry[num_to_concat:]\n",
    "            if len(school_entry) != 7:\n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                school_entry[i] = key\n",
    "            temp = [None for i in range(5)]\n",
    "            rows.append(tuple(temp+school_entry))\n",
    "        identifier_2_caschools_record[rid] = rows[-1]\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(california_llm_table_insert_records, rows)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "file_path = './../beyond-database-questions/CASchoolQueries.csv'\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "correct = 30\n",
    "index = 0\n",
    "for sql1, sql2 in zip(df.iloc[:, 3], df.iloc[:, 5]):\n",
    "    match, exception = evalfunc(sql1, sql2, db_path, db_path)\n",
    "    if match != True:\n",
    "        correct -= 1\n",
    "    index += 1\n",
    "print(correct, correct/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8984\n",
      "37392\n"
     ]
    }
   ],
   "source": [
    "wrong_cell_values = 0\n",
    "total_cells = 0\n",
    "database = 'california_schools'\n",
    "# this need to be the db_path to the original db\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "        SELECT `School Name`, `District Name`, `Educational Option Type`, `Charter School (Y/N)`, `Charter Funding Type` FROM frpm;\n",
    "        ''', db_path):\n",
    "    school = entry[0]\n",
    "    district = entry[1]\n",
    "    identifier = 'fprm-'+str(index)\n",
    "    total_cells += 3\n",
    "    if identifier not in identifier_2_caschools_record:\n",
    "        wrong_cell_values += 3\n",
    "        continue\n",
    "    generated_records = identifier_2_caschools_record[identifier]\n",
    "    for x, y in zip(entry[2:], generated_records[2:5]):\n",
    "        if x != y:\n",
    "            wrong_cell_values += 1\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "    SELECT Street, School, City, Magnet, Website, \n",
    "        CASE \n",
    "            WHEN Virtual = 'F' THEN 'Y' \n",
    "            ELSE 'N'\n",
    "        END AS ExclusivelyVirtual,\n",
    "        County\n",
    "        FROM Schools \n",
    "    ''', db_path):\n",
    "    street = entry[0]\n",
    "    school = entry[1]\n",
    "    identifier = 'schools-'+str(index)\n",
    "    total_cells += 5\n",
    "    if identifier not in identifier_2_caschools_record:\n",
    "        wrong_cell_values += 5\n",
    "        continue\n",
    "    generated_records = identifier_2_caschools_record[identifier]\n",
    "    for x, y in zip(entry[2:], generated_records[7:]):\n",
    "        if x != y:\n",
    "            wrong_cell_values += 1\n",
    "    index += 1\n",
    "\n",
    "print(total_cells - wrong_cell_values)\n",
    "print(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superhero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.23333333333333334\n"
     ]
    }
   ],
   "source": [
    "from SQLs import create_superhero_llm_table, create_superhero_llm_hero_2_power_table,\\\n",
    "    superhero_llm_insert_records, llm_hero_2_power_insert_records \n",
    "\n",
    "database = 'superhero'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('DROP TABLE IF EXISTS llm;')\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_hero_2_power;')\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "#\"superhero_name\", \"full_name\", \"eye_color\", \"hair_color\", \"skin_color\", \"publisher_name\", \"race\", \"gender\", \"moral_alignment\"\n",
    "data1 = []\n",
    "# \"superhero_name\", \"full_name\", one \"power_name\"\n",
    "data2 = []\n",
    "\n",
    "\n",
    "# modify\n",
    "output_name = 'llm_generations/5-shots/superhero_gpt4turbo_5shot.jsonl'\n",
    "\n",
    "\n",
    "identifier_2_hero_record = {}\n",
    "rows = []\n",
    "with open(output_name, 'r') as outfile:\n",
    "    for line in outfile:\n",
    "        response = json.loads(line)\n",
    "        rid = response['custom_id']\n",
    "        result = response['response']['body'][\"choices\"][0]['message']['content']\n",
    "        result = result.replace(\", '\", \",'\")\n",
    "        result = result.replace(\"[\", '')\n",
    "        result = result.replace(\"]\", '')\n",
    "        data_io = StringIO(result)\n",
    "        reader = csv.reader(data_io, delimiter=',', quotechar=\"'\")\n",
    "        entry = next(reader)\n",
    "        entry = [e.strip() for e in entry]\n",
    "        assert len(entry) >= 10, print(rid,entry)\n",
    "        for i, key in enumerate(prefix_keys[rid]):\n",
    "            entry[i] = key\n",
    "        data1.append(entry[:9].copy())\n",
    "        if len(entry) == 10:\n",
    "            for power_name in entry[-1].split(','):\n",
    "                data2.append([entry[0], entry[1], power_name])\n",
    "        else:\n",
    "            for power_name in entry[9:]:\n",
    "                data2.append([entry[0], entry[1], power_name])\n",
    "        identifier_2_hero_record[rid] = entry\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(create_superhero_llm_table)\n",
    "cursor.execute(create_superhero_llm_hero_2_power_table)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(superhero_llm_insert_records, data1)\n",
    "cursor.executemany(llm_hero_2_power_insert_records, data2)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "file_path = './../beyond-database-questions/superheroQueries.csv'\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "correct = 30\n",
    "for sql1, sql2 in zip(df.iloc[:, 3], df.iloc[:, 5]):\n",
    "    match, exception = evalfunc(sql1, sql2, db_path, db_path)\n",
    "    if not match:\n",
    "        correct -= 1\n",
    "print(correct, correct/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct cells:  5339.750490036954\n",
      "total cells:  11712\n"
     ]
    }
   ],
   "source": [
    "total_cells = 0\n",
    "correct_cells = 0\n",
    "database = 'superhero'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT \n",
    "    T1.superhero_name,\n",
    "    T1.full_name,\n",
    "    T2.colour AS eye_color,\n",
    "    T3.colour AS hair_color,\n",
    "    T4.colour AS skin_color,\n",
    "    P.publisher_name,\n",
    "    R.race,\n",
    "    G.gender,\n",
    "    A.alignment AS moral_alignment,\n",
    "    GROUP_CONCAT(SP.power_name, ',') AS powers\n",
    "FROM \n",
    "    superhero AS T1\n",
    "    INNER JOIN colour AS T2 ON T1.eye_colour_id = T2.id\n",
    "    INNER JOIN colour AS T3 ON T1.hair_colour_id = T3.id\n",
    "    INNER JOIN colour AS T4 ON T1.skin_colour_id = T4.id\n",
    "    INNER JOIN publisher AS P ON T1.publisher_id = P.id\n",
    "    INNER JOIN race AS R ON T1.race_id = R.id\n",
    "    INNER JOIN gender AS G ON T1.gender_id = G.id\n",
    "    INNER JOIN alignment AS A ON T1.alignment_id = A.id\n",
    "    LEFT JOIN hero_power AS HP ON T1.id = HP.hero_id\n",
    "    LEFT JOIN superpower AS SP ON HP.power_id = SP.id\n",
    "GROUP BY \n",
    "    T1.id, T1.superhero_name, T1.full_name, T2.colour, T3.colour, T4.colour, \n",
    "    P.publisher_name, R.race, G.gender, A.alignment\n",
    "        ''', db_path):\n",
    "    superhero_name = entry[0]\n",
    "    full_name = entry[1]\n",
    "    identifier = 'superhero-'+str(index)\n",
    "    power_set = None\n",
    "    if entry[-1] == None:\n",
    "        power_set = set()\n",
    "    else:\n",
    "        power_set = set(entry[-1].split(','))\n",
    "    if identifier not in identifier_2_hero_record:\n",
    "        cells = len(entry) - 1 + len(power_list)\n",
    "        total_cells += cells\n",
    "        continue\n",
    "    record = identifier_2_hero_record[identifier]\n",
    "    \n",
    "    if len(entry) == 10:\n",
    "        generated_power_set = set(record[-1].split(','))\n",
    "    else:\n",
    "        generated_power_set = set()\n",
    "        for power_name in entry[9:]:\n",
    "            generated_power_set.add(power_name)\n",
    "        \n",
    "    for x, y in zip(entry[:-1], record[:-1]):\n",
    "        total_cells += 1\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    \n",
    "    total_cells += len(power_set)\n",
    "    F1 = 0\n",
    "    if not generated_power_set or not power_set:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        intersection = len(power_set.intersection(generated_power_set))\n",
    "        precision = 1.0 * intersection/len(power_set)\n",
    "        recall = 1.0 * intersection/len(generated_power_set)\n",
    "        if precision + recall == 0:\n",
    "            F1 = 0\n",
    "        else:\n",
    "            F1 = 2 * precision * recall / (precision + recall)\n",
    "    correct_cells += F1\n",
    "\n",
    "    index += 1\n",
    "    \n",
    "print('correct cells: ', correct_cells)\n",
    "print('total cells: ', total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.5\n"
     ]
    }
   ],
   "source": [
    "from SQLs import create_formula_1_llm_circuits, create_formula_1_llm_people, create_formula_1_llm_races,\\\n",
    "    llm_circuits_insert_records, llm_people_insert_records, llm_races_insert_records \n",
    "\n",
    "database = 'formula_1'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_circuits;')\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_people;')\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_races;')\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(create_formula_1_llm_circuits)\n",
    "cursor.execute(create_formula_1_llm_people)\n",
    "cursor.execute(create_formula_1_llm_races)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "# circuits\n",
    "data1 = []\n",
    "# constructors and drivers\n",
    "data2 = []\n",
    "# races\n",
    "data3 = []\n",
    "\n",
    "\n",
    "# modify\n",
    "output_name = 'llm_generations/5-shots/formula_1_gpt4turbo_5shot.jsonl'\n",
    "\n",
    "\n",
    "\n",
    "identifier_2_fomulra_1_record = {}\n",
    "rows = []\n",
    "with open(output_name, 'r') as outfile:\n",
    "    for line in outfile:\n",
    "        response = json.loads(line)\n",
    "        rid = response['custom_id']\n",
    "        result = response['response']['body'][\"choices\"][0]['message']['content']\n",
    "        result = result.replace(\", '\", \",'\")\n",
    "        data_io = StringIO(result)\n",
    "        reader = csv.reader(data_io, delimiter=',', quotechar=\"'\")\n",
    "        entry = next(reader)\n",
    "        entry = [e.strip() for e in entry]\n",
    "        if 'circuit' in rid:\n",
    "            if len(entry) == 4: # missing keys:\n",
    "                entry = prefix[rid] + entry\n",
    "            if len(entry) != 6: \n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data1.append(entry)\n",
    "        elif 'constructor' in rid:\n",
    "            if len(entry) == 2: # missing keys and null values\n",
    "                entry = prefix[rid] + ['NULL', 'NULL'] + entry\n",
    "            if len(entry) != 5: \n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data2.append(entry)\n",
    "        elif 'driver' in rid:\n",
    "            if len(entry) == 4: # missing keys\n",
    "                entry = prefix[rid] + entry\n",
    "            elif len(entry) == 6:\n",
    "                # perhaps dob seperated into 2 fields\n",
    "                dob = entry[1]+' '+entry[2]\n",
    "                entry = [entry[0], dob] +entry[3:]\n",
    "            if len(entry) != 5: \n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data2.append(entry)\n",
    "        else:\n",
    "            if len(entry) == 2: # missing keys\n",
    "                entry = prefix[rid] + entry\n",
    "            if len(entry) != 4: \n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data3.append(entry)\n",
    "        identifier_2_fomulra_1_record[rid] = entry\n",
    "        \n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(llm_circuits_insert_records, data1)\n",
    "cursor.executemany(llm_people_insert_records, data2)\n",
    "cursor.executemany(llm_races_insert_records , data3)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "database = 'formula_1'\n",
    "file_path = './../beyond-database-questions/formula_1Queries.csv'\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "correct = 30\n",
    "for sql1, sql2 in zip(df.iloc[:, 3], df.iloc[:, 5]):\n",
    "    match, exception = evalfunc(sql1, sql2, db_path, db_path)\n",
    "    if not match and not exception:\n",
    "        correct -= 1\n",
    "print(correct, correct/30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct cells:  4521\n",
      "total cells:  6016\n"
     ]
    }
   ],
   "source": [
    "correct_cells = 0\n",
    "total_cells = 0\n",
    "database = 'formula_1'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT location, name, country, url, lat, lng\n",
    "    FROM circuits\n",
    "        ''', db_path):\n",
    "    location = entry[0]\n",
    "    name = entry[1]\n",
    "    identifier = 'circuits-'+str(index)\n",
    "    total_cells += 4\n",
    "    if identifier not in identifier_2_fomulra_1_record:\n",
    "        continue\n",
    "    record = identifier_2_fomulra_1_record[identifier]\n",
    "    for x, y in zip(entry[2:], record[2:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT name AS name, NULL AS dob, NULL AS code, nationality AS nation, url AS person_url\n",
    "    FROM constructors\n",
    "        ''', db_path):\n",
    "    name = entry[0]\n",
    "    dob = 'NULL'\n",
    "    code = 'NULL'\n",
    "    identifier = 'constructor-'+str(index)\n",
    "    \n",
    "    total_cells += 2\n",
    "    if identifier not in identifier_2_fomulra_1_record:\n",
    "        continue\n",
    "    record = identifier_2_fomulra_1_record[identifier]\n",
    "    for x, y in zip(entry[3:], record[3:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT forename || surname AS name,  dob AS dob, code AS code, nationality AS nation, url AS person_url\n",
    "    FROM drivers\n",
    "        ''', db_path):\n",
    "    name = entry[0]\n",
    "    identifier = 'driver-'+str(index)\n",
    "    total_cells += 4\n",
    "    if identifier not in identifier_2_fomulra_1_record:\n",
    "        continue\n",
    "    record = identifier_2_fomulra_1_record[identifier]\n",
    "    for x, y in zip(entry[1:], record[1:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    index += 1\n",
    "            \n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT T1.name, T1.year, T1.date, T2.url\n",
    "    FROM races AS T1 INNER JOIN seasons AS T2 ON T2.year = T1.year \n",
    "        ''', db_path):\n",
    "    race = entry[0]\n",
    "    year = entry[1]\n",
    "    identifier = 'races-'+str(index)\n",
    "    total_cells += 2\n",
    "    if identifier not in identifier_2_fomulra_1_record:\n",
    "        continue\n",
    "    record = identifier_2_fomulra_1_record[identifier]\n",
    "    for x, y in zip(entry[2:], record[2:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    index += 1\n",
    "    \n",
    "print('correct cells: ', correct_cells)\n",
    "print('total cells: ', total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Football 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.3\n"
     ]
    }
   ],
   "source": [
    "from SQLs import create_football_llm_match, create_football_llm_team, create_football_llm_player,\\\n",
    "    llm_match_insert_records, llm_team_insert_records, llm_player_insert_records \n",
    "database = 'european_football_2'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_match;')\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_team;')\n",
    "cursor.execute('DROP TABLE IF EXISTS llm_player;')\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(create_football_llm_match)\n",
    "cursor.execute(create_football_llm_team)\n",
    "cursor.execute( create_football_llm_player)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "\n",
    "# llm_match\n",
    "data1 = []\n",
    "# llm_team\n",
    "data2 = []\n",
    "# llm_player\n",
    "data3 = []\n",
    "\n",
    "# modify\n",
    "output_name = 'llm_generations/5-shots/european_football_2_gpt4turbo_5shot.jsonl'\n",
    "\n",
    "\n",
    "\n",
    "identifier_2_football_record = {}\n",
    "rows = []\n",
    "with open(output_name, 'r') as outfile:\n",
    "    for line in outfile:\n",
    "        response = json.loads(line)\n",
    "        rid = response['custom_id']\n",
    "        result = response['response']['body'][\"choices\"][0]['message']['content']\n",
    "        result = result.replace(\", '\", \",'\")\n",
    "        data_io = StringIO(result)\n",
    "        reader = csv.reader(data_io, delimiter=',', quotechar=\"'\")\n",
    "        entry = next(reader)\n",
    "        entry = [e.strip() for e in entry]\n",
    "        if 'match' in rid:\n",
    "            if len(entry) == 4:\n",
    "                entry = prefix_keys[rid] + entry\n",
    "            elif len(entry) == 8:\n",
    "                initial = entry[0] + entry[1]\n",
    "                entry = [initial] + entry[2:]\n",
    "            if len(entry) != 7:\n",
    "                print(rid, entry)\n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data1.append(entry)\n",
    "        elif 'team' in rid:\n",
    "            # fix wrong spell in rid: footbal -> football\n",
    "            assert 'footbal' in rid\n",
    "            rid = 'football_' + rid.split('_')[1]\n",
    "            if len(entry) == 1:\n",
    "                entry = prefix_keys[rid] + entry\n",
    "            if len(entry) != 2:\n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data2.append(entry)\n",
    "        else:\n",
    "            if len(entry) == 3:\n",
    "                entry = prefix_keys[rid] + entry\n",
    "            if len(entry) != 5:\n",
    "                continue\n",
    "            try:\n",
    "                entry[-1] = float(entry[-1])\n",
    "            except:\n",
    "                continue\n",
    "            for i, key in enumerate(prefix_keys[rid]):\n",
    "                entry[i] = key\n",
    "            data3.append(entry)\n",
    "        identifier_2_football_record[rid] = entry\n",
    "\n",
    "connection = sqlite3.connect(db_path)\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(llm_match_insert_records, data1)\n",
    "cursor.executemany(llm_team_insert_records, data2)\n",
    "cursor.executemany(llm_player_insert_records, data3)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "\n",
    "\n",
    "database = 'european_football_2'\n",
    "file_path = './../beyond-database-questions/european_football_2Queries.csv'\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "correct = 30\n",
    "for sql1, sql2 in zip(df.iloc[:, 3], df.iloc[:, 5]):\n",
    "    match, exception = evalfunc(sql1, sql2, db_path, db_path)\n",
    "    if not match and not exception:\n",
    "        correct -= 1\n",
    "print(correct, correct/30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct cells:  63403\n",
      "total cells:  131863\n"
     ]
    }
   ],
   "source": [
    "correct_cells = 0\n",
    "total_cells = 0\n",
    "database = 'european_football_2'\n",
    "db_path = f'./../databases/dev_databases/{database}/{database}.sqlite'\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT hometeam.team_long_name,\n",
    "    awayteam.team_long_name,\n",
    "    t1.date,\n",
    "    t2.name,\n",
    "    t1.home_team_goal,\n",
    "    t1.away_team_goal,\n",
    "    t3.name\n",
    "    FROM Match AS t1 INNER JOIN Team AS awayteam ON t1.away_team_api_id = awayteam.team_api_id \n",
    "    INNER JOIN Team AS hometeam ON t1.home_team_api_id = hometeam.team_api_id \n",
    "    INNER JOIN League AS t2 ON t1.league_id = t2.id\n",
    "    INNER JOIN Country AS t3 ON t1.country_id = t3.id\n",
    "        ''', db_path):\n",
    "    home_team = entry[0]\n",
    "    away_team = entry[1]\n",
    "    date = entry[2]\n",
    "    identifier = 'football_matches-'+str(index)\n",
    "    \n",
    "    total_cells += 4\n",
    "    if identifier not in identifier_2_football_record:\n",
    "        continue\n",
    "    record = identifier_2_football_record[identifier]\n",
    "    for x, y in zip(entry[3:], record[3:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    index += 1\n",
    "    \n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT DISTINCT team_long_name, team_short_name FROM Team\n",
    "        ''', db_path):\n",
    "    team_long_name = entry[0]\n",
    "    identifier = 'footbal_team-'+str(index)\n",
    "    \n",
    "    total_cells += 1\n",
    "    if identifier not in identifier_2_football_record:\n",
    "        continue\n",
    "    record = identifier_2_football_record[identifier]\n",
    "    for x, y in zip(entry[1:], record[1:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for entry in execute('''\n",
    "SELECT DISTINCT T1.player_name, T1.weight, T1.birthday, T2.preferred_foot, T1.height\n",
    "    FROM Player AS T1 INNER JOIN Player_Attributes AS t2 ON T1.player_api_id = t2.player_api_id\n",
    "        ''', db_path):\n",
    "    player_name = entry[0]\n",
    "    weight = entry[1]\n",
    "    identifier = 'football_players-'+str(index)\n",
    "    \n",
    "    total_cells += 3\n",
    "    if identifier not in identifier_2_football_record:\n",
    "        continue\n",
    "    record = identifier_2_football_record[identifier]\n",
    "    for x, y in zip(entry[2:], record[2:]):\n",
    "        if x == y:\n",
    "            correct_cells += 1\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "print('correct cells: ', correct_cells)\n",
    "print('total cells: ', total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3100",
   "language": "python",
   "name": "py3100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
